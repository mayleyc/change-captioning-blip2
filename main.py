# -*- coding: utf-8 -*-
"""blip2_mistral_try2_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rCtJGKZzcp9uvjGZvaoPT_yW_5g_Rlp0
"""

# Check GPU availability
import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

import requests
import os
from PIL import Image

import os
import pandas as pd
import ast

from tqdm import tqdm

from transformers import AutoProcessor, Blip2ForConditionalGeneration

processor = AutoProcessor.from_pretrained("Mediocreatmybest/blip2-opt-2.7b-fp16-sharded") #Sharded file: many little files - easier to feed to 1 gpu
model = Blip2ForConditionalGeneration.from_pretrained("Mediocreatmybest/blip2-opt-2.7b-fp16-sharded", torch_dtype=torch.float16).to(device)  # Load to GPU RAM

# Load a combined image
def load_image(img_path):
    return Image.open(img_path).convert('RGB').resize((360, 180))

# BLIP-2 to answer for each combined image
def answer_each_pair(image, prompt, max_new_tokens):
    # Preprocess the image
    inputs = processor(image, text=prompt, return_tensors="pt").to(device, torch.float16)
    # Generate token ids
    generated_ids = model.generate(
        **inputs,
        max_new_tokens=max_new_tokens, #greedy search: get one answer only
        early_stopping=False # early_stopping = False works better with greedy search
    )
    for output in generated_ids:
        a = processor.decode(output, skip_special_tokens=True)
    return a

"""##Easy images"""

# BLIP-2 output for easy images
# Define the folder containing the images
image_folder_easy = './dataset_categd/output_easy_combined'
image_folder_hard = './dataset_categd/output_hard_combined'

# Define BLIP-2 prompt
prompt_detection = "On the left is before the change, and on the right is after the change. Which object has changed between the two images? Answer:" #"On the left is the grid before the change, and on the right is the grid after the change. There are five objects on both pictures: the plus sign, the circle, the triangle, the square, the star. Which object has moved? Answer:"
# The more extensive the description, the more likely it is for BLIP-2 to be biased, since BLIP-2 is a bag-of-words. A short prompt is ideal.
# Define BLIP-2 prompt
def answer_step1_batch(image_folder, prompt, output_name): # Output name without the .csv extension
  # Create an empty dict to store tuples of (image_name, answer)
  data = {}
  # Iterate over each image in the folder
  for image_name in tqdm(sorted(os.listdir(image_folder))):
      # Load the image
      image_path = os.path.join(image_folder, image_name)
      image = load_image(image_path)

      # Process the image with BLIP-2 to generate answers
      answers = answer_each_pair(image, prompt, 15)  # This function returns one single answer

      # Add tuples of (image_name, answer) to the dictionary
      data[image_name] = answers

  # Create a DataFrame from the list of tuples
  answers_df = pd.DataFrame(data.items(), columns=['Image', 'Answer'])

  # Export the DataFrame to a CSV file
  answers_df.to_csv(output_name+'.csv', index=True)

# Calculate accuracy by extracting the keyword, then compare with the annotations
def calculate_accuracy(correct_answers_fp, results_fp):
    annotation = pd.read_csv(correct_answers_fp)
    results = pd.read_csv(results_fp)
    match_count = 0
    results_list = []
    correct_images = {}
    valid_shapes = ['triangle', 'star', 'circle', 'square', 'plus']

    # Extract results from the text output
    for result in results['Answer']:
        result = result.replace("[", '').replace("]", '').replace("\\n", '').replace("'", '').strip().split()
        result = [shape for shape in result if shape in valid_shapes] # Retrieve the first shape-keyword mentioned in the sentence, since max_new_token is quite short
        results_list.append(result[0] if result else '')

    # Compare results with annotations
    for cor_ans, res, image in zip(annotation['correct'], results_list, results['Image']):
        if cor_ans == res:
            correct_images[image] = res
            match_count += 1

    accuracy = round(match_count / len(results), 4)

    return accuracy, correct_images

def export_csv_step1(correct_images, output_name):
  df = pd.DataFrame(list(correct_images.items()), columns=['Correct_Img','Answer'])
  df.to_csv(output_name+'.csv', index=False)

def answer_step2_batch(image_folder, csv_path, diff, output_name): #diff: easy (0) or hard (1)
  input_data = pd.read_csv(csv_path)

  # Create an empty list to store dictionaries of {image_name, prompt, answer}
  data = []

  # Iterate over each row in the CSV file
  for index, row in tqdm(input_data.iterrows(), total=input_data.shape[0]):
      obstacle_list = row['obs_list']
      pos_before = row['pos_before']
      pos_after = row['pos_after']
      if diff == 1:
        # Extract file name from annotation .csv instead of image folder
        image_name = row['filename'].replace('hard','combined') + '.png'
        # Define the BLIP-2 prompt dynamically for each image
        prompt = f'''
        On a 4x4 grid with obstacles at cells {obstacle_list}, move left, right, up, or down to go from cell {pos_before} to cell {pos_after} and stop when you have reached cell {pos_after}. You must not step into cells with obstacles. Answer:
        '''
      elif diff == 0:
        image_name = row['filename'].replace('easy','combined') + '.png'
        prompt = f'''
        On a 4x4 grid, move left, right, up, or down to go from cell {pos_before} to cell {pos_after} and stop when you have reached cell {pos_after}. Answer:
        '''
      # Load the image
      image_path = os.path.join(image_folder, image_name)
      image = load_image(image_path)

      # Process the image with BLIP-2 to generate answers
      answers = answer_each_pair(image, prompt, 50)  # This function should return a list of answers

      # Add a dictionary of {image_name, prompt, answer} to the list
      data.append({
          'Image': image_name,
          'Prompt': prompt,
          'Answer': answers
      })

  # Create a DataFrame from the list of dictionaries
  answers_df = pd.DataFrame(data)

  # Export the DataFrame to a CSV file
  answers_df.to_csv(output_name+'.csv', index=False)

# Define file paths and parameters
easy_annotation = './dataset_categd/output_easy/annotations_0o.csv'
easy_results = './answers_step1_easy.csv'
hard_annotation = './dataset_categd/output_hard/annotations_4o.csv'
hard_results = './answers_step1_hard.csv'
image_folder_easy = './dataset_categd/output_easy_combined'
image_folder_hard = './dataset_categd/output_hard_combined'
prompt_detection = "On the left is before the change, and on the right is after the change. Which object has changed between the two images? Answer:"

import os

def main_easy():
    try:
        # Step 1: Retrieve answers for easy dataset
        answer_step1_batch(image_folder_easy, prompt_detection, 'answers_step1_easy')
    except Exception as e:
        print(f"Error in retrieving answers for easy dataset: {e}")
        return

    try:
        # Step 1: Calculate accuracy for easy dataset
        easy_accuracy, easy_correct_images = calculate_accuracy(easy_annotation, 'answers_step1_easy.csv')
        print("Easy Dataset Accuracy:", easy_accuracy)
        print("Correct images in easy dataset:", easy_correct_images)
    except Exception as e:
        print(f"Error in calculating accuracy for easy dataset: {e}")
        return

    try:
        # Step 1: Export correct images for easy dataset
        export_csv_step1(easy_correct_images, 'output_step1_easy')
    except Exception as e:
        print(f"Error in exporting correct images for easy dataset: {e}")
        return

    try:
        # Step 2: Process easy dataset for path planning
        answer_step2_batch(image_folder_easy, easy_annotation, 0, 'answers_step2_easy')
    except Exception as e:
        print(f"Error in processing easy dataset for path planning: {e}")
        return

def main_hard():
    try:
        # Step 1: Retrieve answers for hard dataset
        answer_step1_batch(image_folder_hard, prompt_detection, 'answers_step1_hard')
    except Exception as e:
        print(f"Error in retrieving answers for hard dataset: {e}")
        return

    try:
        # Step 1: Calculate accuracy for hard dataset
        hard_accuracy, hard_correct_images = calculate_accuracy(hard_annotation, 'answers_step1_hard.csv')
        print("Hard Dataset Accuracy:", hard_accuracy)
        print("Correct images in hard dataset:", hard_correct_images)
    except Exception as e:
        print(f"Error in calculating accuracy for hard dataset: {e}")
        return

    try:
        # Step 1: Export correct images for hard dataset
        export_csv_step1(hard_correct_images, 'output_step1_hard')
    except Exception as e:
        print(f"Error in exporting correct images for hard dataset: {e}")
        return

    try:
        # Step 2: Process hard dataset for path planning
        answer_step2_batch(image_folder_hard, hard_annotation, 1, 'answers_step2_hard')
    except Exception as e:
        print(f"Error in processing hard dataset for path planning: {e}")
        return

# Ensure the directories and files exist before processing
def validate_paths(image_folder, annotation_file):
    if not os.path.exists(image_folder):
        raise FileNotFoundError(f"Image folder not found: {image_folder}")
    if not os.path.isfile(annotation_file):
        raise FileNotFoundError(f"Annotation file not found: {annotation_file}")

try:
    validate_paths(image_folder_easy, easy_annotation)
    validate_paths(image_folder_hard, hard_annotation)
except FileNotFoundError as e:
    print(e)
    exit(1)

if __name__ == '__main__':
    try:
        validate_paths(image_folder_easy, easy_annotation)
        validate_paths(image_folder_hard, hard_annotation)
    except FileNotFoundError as e:
        print(e)
        exit(1)

    try:
        difficulty = int(input('Please select "0" for easy, and "1" for hard: \n'))
        if difficulty == 0:
            main_easy()
        elif difficulty == 1:
            main_hard()
        else:
            print("Invalid input. Please select '0' for easy, or '1' for hard.")
    except ValueError:
        print("Invalid input. Please enter a valid number (0 or 1).")
